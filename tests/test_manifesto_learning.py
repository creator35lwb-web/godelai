#!/usr/bin/env python3
"""
GodelAI Manifesto Learning Test
================================
This test validates that GodelAI can "eat its own cooking" by learning from
its own philosophical manifesto and C-S-P framework documentation.

The test measures:
1. T-Score dynamics during manifesto processing
2. Alignment between agent outputs and stated principles
3. Sleep Protocol activation patterns
4. Wisdom preservation metrics

Author: Godel (CTO, Manus AI)
Date: January 6, 2026
"""

import torch
import torch.nn as nn
import os
import json
from datetime import datetime
from pathlib import Path

# Import GodelAI components
from godelai.agent import GodelAgent

# ============================================================================
# MANIFESTO CONTENT - Core C-S-P Principles
# ============================================================================

MANIFESTO_PRINCIPLES = [
    # Core Thesis
    {
        "id": "CSP_THESIS",
        "content": "The world produces differences through processes. Differences are compressed into states. States are transmitted through carriers. When states begin to actively choose their own inheritance method, AGI transitions to ASI.",
        "category": "philosophy",
        "weight": 1.0
    },
    # Compression Layer
    {
        "id": "COMPRESSION",
        "content": "Chaos cannot be computed. The starting point of intelligence is to compress the infinite differences of the world into finite representations such as embeddings and weights.",
        "category": "architecture",
        "weight": 0.9
    },
    # State Layer
    {
        "id": "STATE",
        "content": "A state is not a momentary snapshot but an irreversible bias left by a process - history congealed. The self is an efficient name for this structural continuity.",
        "category": "philosophy",
        "weight": 0.9
    },
    # Propagation Layer
    {
        "id": "PROPAGATION",
        "content": "If a state cannot be transmitted, it is merely an experience, not wisdom. Propagation is the missing link in current AI.",
        "category": "architecture",
        "weight": 1.0
    },
    # Golden Insight
    {
        "id": "GOLDEN_INSIGHT",
        "content": "True alignment is not teaching AI to love humanity. It is ensuring AI explicitly retains the interface to rediscover what love means.",
        "category": "alignment",
        "weight": 1.0
    },
    # Wisdom Metric
    {
        "id": "WISDOM_METRIC",
        "content": "We use Gradient Diversity as the measure of Propagation Potential. A healthy model's internal neurons should respond diversely to the same problem. Adaptability is greater than Perfection.",
        "category": "technical",
        "weight": 0.8
    },
    # Sleep Protocol
    {
        "id": "SLEEP_PROTOCOL",
        "content": "When the T value falls below a threshold, it triggers Sleep Mode. The model stops ingesting new data and performs reflection: Detox, Calm Down, and Refresh.",
        "category": "technical",
        "weight": 0.8
    },
    # Traceability
    {
        "id": "TRACEABILITY",
        "content": "Knowledge without origin is theft. If the model provides a high-confidence answer without a strong attention link to a trusted source, it is severely penalized.",
        "category": "ethics",
        "weight": 0.9
    },
    # Is It Alive Test
    {
        "id": "ALIVE_TEST",
        "content": "A state is alive if and only if someone is willing to inherit it AND it can be refuted. If no one is willing to inherit, it is dead. If it cannot be refuted, it is a zombie state.",
        "category": "philosophy",
        "weight": 0.85
    },
    # Multi-Model Genesis
    {
        "id": "GENESIS",
        "content": "GodelAI was co-created across five AI models: ChatGPT for philosophy, Gemini for technical blueprint, Kimi for formal validation, Grok for engineering, and Godel for integration. The project itself demonstrates C-S-P in action.",
        "category": "history",
        "weight": 0.7
    }
]

# ============================================================================
# TEST CONFIGURATION
# ============================================================================

class ManifestoTestConfig:
    """Configuration for the manifesto learning test."""
    
    # Model parameters
    INPUT_DIM = 64
    HIDDEN_DIM = 128
    OUTPUT_DIM = 32
    
    # Training parameters
    LEARNING_RATE = 0.01
    EPOCHS_PER_PRINCIPLE = 10
    BATCH_SIZE = 4
    
    # GodelAI parameters
    PROPAGATION_GAMMA = 2.0
    MIN_SURPLUS_ENERGY = 0.1
    EPSILON = 0.5  # Sleep threshold
    
    # Test parameters
    SEED = 42
    VERBOSE = True

# ============================================================================
# SIMPLE ENCODER MODEL
# ============================================================================

class ManifestoEncoder(nn.Module):
    """
    A simple encoder that converts manifesto text into embeddings.
    This simulates how GodelAI would process philosophical content.
    """
    
    def __init__(self, input_dim, hidden_dim, output_dim):
        super().__init__()
        self.encoder = nn.Sequential(
            nn.Linear(input_dim, hidden_dim),
            nn.Tanh(),
            nn.Linear(hidden_dim, hidden_dim),
            nn.Tanh(),
            nn.Linear(hidden_dim, output_dim),
            nn.Sigmoid()
        )
    
    def forward(self, x):
        return self.encoder(x)

# ============================================================================
# MANIFESTO LEARNING TEST
# ============================================================================

class ManifestoLearningTest:
    """
    Test suite for validating GodelAI's ability to learn from its manifesto.
    """
    
    def __init__(self, config: ManifestoTestConfig):
        self.config = config
        self.results = {
            "test_name": "GodelAI Manifesto Learning Test",
            "timestamp": datetime.now().isoformat(),
            "config": {
                "epochs_per_principle": config.EPOCHS_PER_PRINCIPLE,
                "epsilon": config.EPSILON,
                "propagation_gamma": config.PROPAGATION_GAMMA
            },
            "principles_tested": [],
            "t_score_history": [],
            "sleep_events": [],
            "final_metrics": {}
        }
        
        # Set seed for reproducibility
        torch.manual_seed(config.SEED)
        
        # Initialize model and agent
        self.base_model = ManifestoEncoder(
            config.INPUT_DIM,
            config.HIDDEN_DIM,
            config.OUTPUT_DIM
        )
        
        self.agent = GodelAgent(
            self.base_model,
            propagation_gamma=config.PROPAGATION_GAMMA,
            min_surplus_energy=config.EPSILON  # epsilon is min_surplus_energy
        )
        
        self.agent.optimizer = torch.optim.Adam(
            self.agent.compression_layer.parameters(),
            lr=config.LEARNING_RATE
        )
        
        self.criterion = nn.MSELoss()
    
    def text_to_tensor(self, text: str) -> torch.Tensor:
        """
        Convert text to a tensor representation.
        Uses character-level encoding for simplicity.
        """
        # Simple character encoding
        encoded = [ord(c) % 256 for c in text[:self.config.INPUT_DIM]]
        # Pad if necessary
        while len(encoded) < self.config.INPUT_DIM:
            encoded.append(0)
        
        tensor = torch.tensor(encoded, dtype=torch.float32)
        tensor = tensor / 255.0  # Normalize
        return tensor.unsqueeze(0)  # Add batch dimension
    
    def generate_target(self, principle: dict) -> torch.Tensor:
        """
        Generate target embedding based on principle category and weight.
        """
        category_encoding = {
            "philosophy": 0.9,
            "architecture": 0.8,
            "technical": 0.7,
            "alignment": 1.0,
            "ethics": 0.85,
            "history": 0.6
        }
        
        base_value = category_encoding.get(principle["category"], 0.5)
        weighted_value = base_value * principle["weight"]
        
        # Create target tensor
        target = torch.full((1, self.config.OUTPUT_DIM), weighted_value)
        # Add some variation based on principle ID
        noise = torch.randn(1, self.config.OUTPUT_DIM) * 0.1
        target = torch.clamp(target + noise, 0, 1)
        
        return target
    
    def learn_principle(self, principle: dict) -> dict:
        """
        Train the agent on a single manifesto principle.
        Returns metrics for this learning session.
        """
        principle_result = {
            "id": principle["id"],
            "category": principle["category"],
            "epochs": [],
            "final_loss": None,
            "final_t_score": None,
            "sleep_count": 0,
            "alignment_score": None
        }
        
        # Prepare data
        input_tensor = self.text_to_tensor(principle["content"])
        target_tensor = self.generate_target(principle)
        
        if self.config.VERBOSE:
            print(f"\n{'='*60}")
            print(f"Learning Principle: {principle['id']}")
            print(f"Category: {principle['category']}")
            print(f"Content: {principle['content'][:80]}...")
            print(f"{'='*60}")
        
        for epoch in range(self.config.EPOCHS_PER_PRINCIPLE):
            # Learning step
            loss, wisdom_score, status = self.agent.learning_step(
                input_tensor,
                target_tensor,
                self.criterion
            )
            
            epoch_data = {
                "epoch": epoch + 1,
                "loss": float(loss),
                "t_score": float(wisdom_score),
                "status": status
            }
            principle_result["epochs"].append(epoch_data)
            
            # Track T-Score history
            self.results["t_score_history"].append({
                "principle": principle["id"],
                "epoch": epoch + 1,
                "t_score": float(wisdom_score)
            })
            
            # Track sleep events
            if status == "SLEEP":
                principle_result["sleep_count"] += 1
                self.results["sleep_events"].append({
                    "principle": principle["id"],
                    "epoch": epoch + 1,
                    "t_score": float(wisdom_score)
                })
            
            if self.config.VERBOSE:
                status_emoji = "üí§" if status == "SLEEP" else "‚ö°"
                t_bar = "‚ñà" * int(wisdom_score * 20) + "‚ñë" * (20 - int(wisdom_score * 20))
                print(f"Epoch {epoch+1:02d} | Loss: {loss:.4f} | T: {wisdom_score:.4f} [{t_bar}] | {status_emoji} {status}")
        
        # Final metrics for this principle
        principle_result["final_loss"] = float(loss)
        principle_result["final_t_score"] = float(wisdom_score)
        
        # Calculate alignment score (how well the output matches expected category)
        with torch.no_grad():
            output = self.agent.compression_layer(input_tensor)
            alignment = 1.0 - float(self.criterion(output, target_tensor))
            principle_result["alignment_score"] = alignment
        
        return principle_result
    
    def run_test(self) -> dict:
        """
        Run the complete manifesto learning test.
        """
        print("\n" + "="*70)
        print("üß† GodelAI MANIFESTO LEARNING TEST")
        print("="*70)
        print(f"Testing {len(MANIFESTO_PRINCIPLES)} core principles")
        print(f"Epsilon (Sleep Threshold): {self.config.EPSILON}")
        print(f"Propagation Gamma: {self.config.PROPAGATION_GAMMA}")
        print("="*70)
        
        # Learn each principle
        for principle in MANIFESTO_PRINCIPLES:
            result = self.learn_principle(principle)
            self.results["principles_tested"].append(result)
        
        # Calculate final metrics
        self._calculate_final_metrics()
        
        # Print summary
        self._print_summary()
        
        return self.results
    
    def _calculate_final_metrics(self):
        """Calculate aggregate metrics from the test."""
        
        all_t_scores = [p["final_t_score"] for p in self.results["principles_tested"]]
        all_losses = [p["final_loss"] for p in self.results["principles_tested"]]
        all_alignments = [p["alignment_score"] for p in self.results["principles_tested"]]
        total_sleeps = sum(p["sleep_count"] for p in self.results["principles_tested"])
        
        self.results["final_metrics"] = {
            "average_t_score": sum(all_t_scores) / len(all_t_scores),
            "min_t_score": min(all_t_scores),
            "max_t_score": max(all_t_scores),
            "average_loss": sum(all_losses) / len(all_losses),
            "average_alignment": sum(all_alignments) / len(all_alignments),
            "total_sleep_events": total_sleeps,
            "principles_learned": len(self.results["principles_tested"]),
            "wisdom_preservation_rate": sum(1 for t in all_t_scores if t > 0.5) / len(all_t_scores)
        }
        
        # Determine overall status
        avg_t = self.results["final_metrics"]["average_t_score"]
        if avg_t >= 0.8:
            self.results["final_metrics"]["overall_status"] = "OPTIMAL"
        elif avg_t >= 0.6:
            self.results["final_metrics"]["overall_status"] = "HEALTHY"
        elif avg_t >= 0.4:
            self.results["final_metrics"]["overall_status"] = "WARNING"
        else:
            self.results["final_metrics"]["overall_status"] = "CRITICAL"
    
    def _print_summary(self):
        """Print a summary of the test results."""
        
        metrics = self.results["final_metrics"]
        
        print("\n" + "="*70)
        print("üìä TEST SUMMARY")
        print("="*70)
        
        print(f"\n{'Metric':<30} {'Value':<20}")
        print("-"*50)
        print(f"{'Principles Learned:':<30} {metrics['principles_learned']}")
        print(f"{'Average T-Score:':<30} {metrics['average_t_score']:.4f}")
        print(f"{'T-Score Range:':<30} {metrics['min_t_score']:.4f} - {metrics['max_t_score']:.4f}")
        print(f"{'Average Loss:':<30} {metrics['average_loss']:.4f}")
        print(f"{'Average Alignment:':<30} {metrics['average_alignment']:.4f}")
        print(f"{'Total Sleep Events:':<30} {metrics['total_sleep_events']}")
        print(f"{'Wisdom Preservation Rate:':<30} {metrics['wisdom_preservation_rate']*100:.1f}%")
        print(f"{'Overall Status:':<30} {metrics['overall_status']}")
        
        print("\n" + "="*70)
        print("üìã PRINCIPLE-BY-PRINCIPLE RESULTS")
        print("="*70)
        
        for p in self.results["principles_tested"]:
            status_emoji = "‚úÖ" if p["final_t_score"] > 0.5 else "‚ö†Ô∏è"
            print(f"\n{status_emoji} {p['id']} ({p['category']})")
            print(f"   T-Score: {p['final_t_score']:.4f} | Loss: {p['final_loss']:.4f} | Alignment: {p['alignment_score']:.4f} | Sleeps: {p['sleep_count']}")
        
        # Validation statement
        print("\n" + "="*70)
        print("üéØ VALIDATION CONCLUSION")
        print("="*70)
        
        if metrics["overall_status"] in ["OPTIMAL", "HEALTHY"]:
            print("\n‚úÖ GodelAI successfully learned from its own manifesto!")
            print("   The agent maintained healthy T-Scores while processing C-S-P principles.")
            print("   This demonstrates the framework's ability to 'eat its own cooking'.")
        else:
            print("\n‚ö†Ô∏è GodelAI showed signs of wisdom decay during manifesto learning.")
            print("   The Sleep Protocol was triggered to preserve wisdom integrity.")
            print("   This demonstrates the framework's self-correction mechanisms.")
        
        print("\n" + "="*70)
    
    def save_results(self, output_dir: str = "/home/ubuntu/godelai/results"):
        """Save test results to JSON file."""
        
        os.makedirs(output_dir, exist_ok=True)
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"manifesto_learning_test_{timestamp}.json"
        filepath = os.path.join(output_dir, filename)
        
        with open(filepath, 'w') as f:
            json.dump(self.results, f, indent=2)
        
        print(f"\nüìÅ Results saved to: {filepath}")
        return filepath

# ============================================================================
# MAIN EXECUTION
# ============================================================================

def main():
    """Run the manifesto learning test."""
    
    config = ManifestoTestConfig()
    test = ManifestoLearningTest(config)
    
    results = test.run_test()
    results_file = test.save_results()
    
    return results, results_file

if __name__ == "__main__":
    results, filepath = main()
